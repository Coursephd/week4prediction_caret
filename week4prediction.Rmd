---
title: "week4_prediction"
author: "Vinay Mahajan"
date: "December 5, 2016"
output: 
  html_document: 
    keep_md: yes
    number_sections: yes
---

```{r setup, include=FALSE, message =FALSE}
knitr::opts_chunk$set(echo = TRUE, message =FALSE)
```
# Device data analysis
Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement

## Read the data from given location, data cleaning and set-up

[Training.csv](https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv)  
[Testing.csv](https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv)  
```{r Setup and data cleaning, results='hide'}

library(data.table)
library(VIM)
library(Hmisc)
library(caret)
library(ggplot2)

setwd("C:\\Users\\VinayMahajan\\Desktop\\Misc\\Coursera Data Science\\week4machinelearning")

train <- fread("pml-training.csv", na.strings = c("NA", "", " "))
test <- fread("pml-testing.csv", na.strings = c("NA", "", " "))

train2 <- train[, colSums(is.na(train)) == 0, with =FALSE]
train3 <- data.table( na.omit(train2) )

test2 <- test[, colSums(is.na(test)) == 0, with =FALSE]
test3 <- data.table( na.omit(test2) )

dim(train3)
dim(test3)

names(train3)

train4 <- melt(data = train3, 
               id.vars =c("V1", "user_name", "classe",            
                        "raw_timestamp_part_1", "raw_timestamp_part_2",
                        "cvtd_timestamp", "new_window", "num_window" ))

ggplot(train4) + 
  geom_boxplot(aes(x=as.factor(classe), y=value )) +
  facet_wrap(~ variable, scales ="free_y", nrow=5)

aggr(train)
summary(aggr(train3, sortVars = TRUE, plot =FALSE))

```

## Analysis of the available data, splitting of data
In order to get out-of-sample errors, we split the cleaned training set trainData into a training set (train, 70%) for prediction and a validation set (valid 30%) to compute the out-of-sample errors.
```{r split of the data}

train5 <- train3 [,-c(1:7), with = FALSE]
test5 <- test3 [, -c(1:7), with = FALSE]

set.seed(11111)
inTrain <- createDataPartition(train5$classe, p = 0.7, list = FALSE)
train6 <- train5[inTrain, ]
valid6 <- train5[-inTrain, ]

``` 

## Prediction Algorithms
Let using 3 different algorithms

## Method: Generalized Boosted Model
```{r rpart, results = 'hide'}

controllda <- trainControl(method="cv", number=3)
modFitlda <- train(classe ~ ., 
                    data=train6, 
                    method = "lda",
                    trControl=controllda, 
                    verbose = FALSE)
modFitlda$finalModel

predlda <- predict(modFitlda, newdata=valid6)
cmlda <- confusionMatrix(predlda, valid6$classe)

```

## Model: Random forest
```{r Random forest, results = 'hide'}

# model fit
set.seed(11111)
controlRF <- trainControl(method="cv", number=3)
modFitRF <- train(classe ~ ., 
                          data=train6, 
                          method="rf",
                          ntree=100,
                          trControl=controlRF)
modFitRF$finalModel

predRF <- predict(modFitRF, newdata=valid6)
cmRF <- confusionMatrix(predRF, valid6$classe)

```

## Model: GBM
```{r GBM, results = 'hide'}

controlGBM <- trainControl(method="cv", number=3)
modFitGBM <- train(classe ~ ., 
                          data=train6, 
                          method="gbm",
                          trControl=controlGBM)
modFitGBM$finalModel


predGBM <- predict(modFitGBM, newdata=valid6)
cmGBM <- confusionMatrix(predGBM, valid6$classe)

```

## Use accuracy measure to determine best model
```{r}

cmlda
cmGBM
cmRF

Accuracy <- data.frame(
  Model = c('LDA', 'GBM', 'RF'),
  Accuracy = rbind(cmlda$overall[1], cmGBM$overall[1], cmRF$overall[1])
)
print(Accuracy)
```

## Use importance and plot functions from `caret` package
```{r important variables}

importance <- varImp(modFitRF, scale=FALSE)
# summarize importance
print(importance)
# plot importance
plot(importance)

```

As the accuracy is almost 100% the prediction of test data should be quite close to reality
```{r Prediction}

pred <- predict(modFitRF, newdata=test3)
pred02 <- data.frame(
  problem_id=test3$problem_id,
  predicted=pred
)
print(pred02)

```
